<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>CUDA学习记录(一)：基本概念与语法 | 浅眠一梦,不曾醉酒</title><meta name="author" content="Deemod"><meta name="copyright" content="Deemod"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="什么是CUDA？CUDA(Compute Unified Device Architecture)，直译是统一计算设备架构，是NVIDIA发明的一种并行计算平台和编程模型，可利用NVDIA GPU的并行计算能力大幅提升计算性能。 GPU 与 CPU的区别两者的主要区别为：  GPU 并行度更高，有更多的运算单元，擅长处理高度并行的运算，如图像渲染、挖矿。 CPU 通用性更好，有更多的控制与缓存单元">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA学习记录(一)：基本概念与语法">
<meta property="og:url" content="https://sognarere.github.io/2022/05/01/CUDA-1/index.html">
<meta property="og:site_name" content="浅眠一梦,不曾醉酒">
<meta property="og:description" content="什么是CUDA？CUDA(Compute Unified Device Architecture)，直译是统一计算设备架构，是NVIDIA发明的一种并行计算平台和编程模型，可利用NVDIA GPU的并行计算能力大幅提升计算性能。 GPU 与 CPU的区别两者的主要区别为：  GPU 并行度更高，有更多的运算单元，擅长处理高度并行的运算，如图像渲染、挖矿。 CPU 通用性更好，有更多的控制与缓存单元">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2022/05/01/mWXIjvRnOsNQt3g.jpg">
<meta property="article:published_time" content="2022-05-01T06:23:18.000Z">
<meta property="article:modified_time" content="2022-05-08T08:56:43.790Z">
<meta property="article:author" content="Deemod">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/05/01/mWXIjvRnOsNQt3g.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://sognarere.github.io/2022/05/01/CUDA-1/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CUDA学习记录(一)：基本概念与语法',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-08 16:56:43'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="浅眠一梦,不曾醉酒" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2022/04/10/6ogLzb7wAJEplyT.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s2.loli.net/2022/05/01/mWXIjvRnOsNQt3g.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">浅眠一梦,不曾醉酒</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CUDA学习记录(一)：基本概念与语法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-05-01T06:23:18.000Z" title="发表于 2022-05-01 14:23:18">2022-05-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-08T08:56:43.790Z" title="更新于 2022-05-08 16:56:43">2022-05-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/CUDA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">CUDA学习笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CUDA学习记录(一)：基本概念与语法"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="什么是CUDA？"><a href="#什么是CUDA？" class="headerlink" title="什么是CUDA？"></a>什么是CUDA？</h1><p>CUDA(Compute Unified Device Architecture)，直译是统一计算设备架构，是NVIDIA发明的一种并行计算平台和编程模型，可利用NVDIA GPU的并行计算能力大幅提升计算性能。</p>
<h1 id="GPU-与-CPU的区别"><a href="#GPU-与-CPU的区别" class="headerlink" title="GPU 与 CPU的区别"></a>GPU 与 CPU的区别</h1><p><img src="https://s2.loli.net/2022/05/08/Sy7dCpK1NQAImLF.png" alt="GPUCPU.png"><br>两者的主要区别为：</p>
<ol>
<li>GPU 并行度更高，有更多的运算单元，擅长处理高度并行的运算，如图像渲染、挖矿。</li>
<li>CPU 通用性更好，有更多的控制与缓存单元，更擅长逻辑控制，如个人PC。</li>
</ol>
<h1 id="CUDA-编程模型"><a href="#CUDA-编程模型" class="headerlink" title="CUDA 编程模型"></a>CUDA 编程模型</h1><h2 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h2><p>由CUDA扩展的C++(CUDA C++)所定义的函数即为Kernel，当被调用时，它将并行地在N个线程上执行N次，而普通的C++函数则只会执行一次。</p>
<p>通常用__global__来定义Kernel函数，用&lt;&lt;&lt;…&gt;&gt;&gt;来的定义执行Kernel的CUDA线程数，每个线程有唯一的thread ID，可通过Kernel的内置变量访问。</p>
<p>一个简单的例子如下所示，该实例完成了N维向量的加法，每个线程都将执行VecAdd()，函数中通过<em>threadIdx.x</em>获取当前线程的thread ID，以完成对应位置元素相加。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Kernel definition</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">VecAdd</span><span class="params">(<span class="keyword">float</span>* A, <span class="keyword">float</span>* B, <span class="keyword">float</span>* C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = threadIdx.x;</span><br><span class="line">C[i] = A[i] + B[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line"><span class="comment">// Kernel invocation with N threads</span></span><br><span class="line">VecAdd&lt;&lt;&lt;<span class="number">1</span>, N&gt;&gt;&gt;(A, B, C);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="线程层次结构"><a href="#线程层次结构" class="headerlink" title="线程层次结构"></a>线程层次结构</h2><p>为了表达方便，<em>threadIdx</em>被定义为三元素的向量(<em>thread index</em>)，通过<em>thread index</em>就可以获取当前<em>thread ID</em>，这些<em>thread</em>就构成了<em>Block</em>。</p>
<p><em>thread index</em>与<em>thread ID</em>是一一对应的关系，假设一个<em>Block</em>大小为($D_x$,$D_y$，$D_z$),则<em>thread index</em>(x,y,z)对应的<em>thread ID</em> = $x+y\times D_x+z\times D_x D_y$ (跟我们平常定义数组各维度的顺序刚好相反)</p>
<p>由于同一个<em>block</em>上的thread期望在同一个Core上运行，它们将分享Core上有限的memory资源，因此一个<em>block</em>上的线程数是有限的，该上限目前为1024。</p>
<p>以下示例代码完成了矩阵加法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Kernel definition</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">MatAdd</span><span class="params">(<span class="keyword">float</span> A[N][N], <span class="keyword">float</span> B[N][N],</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="keyword">float</span> C[N][N])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = threadIdx.x;</span><br><span class="line"><span class="keyword">int</span> j = threadIdx.y;</span><br><span class="line">C[i][j] = A[i][j] + B[i][j];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line"><span class="comment">// Kernel invocation with one block of N * N * 1 threads</span></span><br><span class="line"><span class="keyword">int</span> numBlocks = <span class="number">1</span>;</span><br><span class="line"><span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(N, N)</span></span>;</span><br><span class="line">MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>一个Kernel可被多个<em>block</em>执行，与<em>tread</em>层级相类似，多个<em>block</em>也可以组成一维、二维、三维的结构，即<em>grid</em>，三者关系如下图所示：<br><img src="https://s2.loli.net/2022/05/08/O2YldMJ4zNfrFbj.png" alt="ThreadHierarchy.png"></p>
<p>以下示例代码展示了由多个block完成的矩阵加法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Kernel definition</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">MatAdd</span><span class="params">(<span class="keyword">float</span> A[N][N], <span class="keyword">float</span> B[N][N],</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="keyword">float</span> C[N][N])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"><span class="keyword">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"><span class="keyword">if</span> (i &lt; N &amp;&amp; j &lt; N)</span><br><span class="line">C[i][j] = A[i][j] + B[i][j];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line"><span class="comment">// Kernel invocation</span></span><br><span class="line"><span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">numBlocks</span><span class="params">(N / threadsPerBlock.x, N / threadsPerBlock.y)</span></span>;</span><br><span class="line">MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>block可以完全独立地执行，即block之间没有依赖，可以以任意顺序被任何一个Core调度，如下图所示：<br><img src="https://s2.loli.net/2022/05/08/xhiMaoBb5Fzkmq2.png" alt="separateExec.png"></p>
<p>同一个<em>block</em>内的thread可通过shared memory来共享数据，也可以通过同步操作来协调内存访问。在kernel中调用内建函数__syncthreads()来声明同步点，该函数相当于一个<em>barrier</em>，所有可以执行到此处的线程都将被阻断在这里，直到它们都执行到这里后才继续执行(Any thread reaching the barrier waits until all of the other threads in that block also reach it. It is designed for avoiding race conditions when loading shared memory, and the compiler will not move memory reads/writes around a __syncthreads())</p>
<p>为了更有效的线程间合作，shared memory具有非常低的延迟（跟L1 cache非常类似），所以__syncthreads()是非常轻量的。</p>
<h2 id="存储层次结构"><a href="#存储层次结构" class="headerlink" title="存储层次结构"></a>存储层次结构</h2><p><img src="https://s2.loli.net/2022/05/08/hEzdmaIRYrlUj61.png" alt="MemHierarchy.png"><br>在执行时<em>thread</em>可访问多种存储空间</p>
<ol>
<li>local memory:<em>thread</em>具有的私有存储空间。</li>
<li>shared memory:同一<em>block</em>中的<em>threads</em>可见</li>
<li>global memory:对所有<em>thread</em>可见</li>
<li>constant memory:对所有<em>thread</em>可见</li>
<li>texture memory：对所有<em>thread</em>可见，为某些特定数据格式提供不同的寻址模式以及数据过滤。<h2 id="异构编程"><a href="#异构编程" class="headerlink" title="异构编程"></a>异构编程</h2><img src="https://s2.loli.net/2022/05/08/Qt7PIor2xuLvizC.png" alt="exec.png"></li>
</ol>
<p>CUDA默认异构执行，GPU作为Host端的协处理器，即相关kernel在GPU端执行，剩下的代码在CPU端执行。</p>
<p>执行程序时，host与device都在DRAM中维护自己独立的内存空间(host memory, device memroy)，通过调用CUDA runtime来管理对kernel可见的global/constant/texture memory，包括device端内存的分配与释放以及host与device端的数据传输。</p>
<p>Unified Memory提供了managed memory来连接host与device的存储空间，managed memory是一段地址连贯的公共存储空间，可被系统中的CPU与GPU访问，这一功能使得编程时无需再显式地在host与device之间传输数据，简化了应用。(实际上还是分开的，只是编程角度看好像统一了)</p>
<h2 id="异步SIMT编程模型"><a href="#异步SIMT编程模型" class="headerlink" title="异步SIMT编程模型"></a>异步SIMT编程模型</h2><p>CUDA编程模型中最底层的执行单元为<em>thread</em>，操作可分为计算操作与访存操作(个人理解)，可通过异步编程模型来加速程序执行过程中的访存操作。</p>
<p>异步编程模型为 CUDA 线程之间的同步定义了异步屏障的行为，该模型还解释并定义了如何使用cuda::memcpy_async 在 GPU 中计算时从全局内存中异步读写数据。</p>
<h3 id="异步操作-这部分没看懂多少！！！！！以后再填坑"><a href="#异步操作-这部分没看懂多少！！！！！以后再填坑" class="headerlink" title="异步操作(这部分没看懂多少！！！！！以后再填坑)"></a>异步操作(这部分没看懂多少！！！！！以后再填坑)</h3><p>异步操作被定义为由一个CUDA线程启动,但看起来像由另一个线程异步执行的操作(An asynchronous operation is defined as an operation that is initiated by a CUDA thread and is executed asynchronously as-if by another thread.)，就像是一个线程里有一个子线程，这个线程可以在一定范围内不按代码顺序执行任务，比如第n行代码正在执行大量数据拷贝，耗时很长，此时就可以先执行下一行代码，而无需一直等待。</p>
<p><strong>注意仅仅是看起来像是有另一个线程，实际上并没有创建新的线程！</strong></p>
<p>在规范的程序中，一个或多个CUDA线程与异步操作同步。启动异步操作的 CUDA线程不需要在同步线程中。</p>
<p>异步线程始终与启动异步操作的CUDA线程相关联，异步操作使用同步对象来同步操作的完成。 这样的同步对象可以由用户显式管理（例如，cuda::memcpy_async）或在库中隐式管理（例如，cooperative_groups::memcpy_async）</p>
<p>同步对象可以是 cuda::barrier 或 cuda::pipeline。这些同步对象可以在不同的thread scope内使用。scope定义了可以使用同步对象与异步操作同步的线程集合。下表定义了 CUDA C++ 中可用的线程范围以及可以与之同步的线程。</p>
<table>
<thead>
<tr>
<th>Thread scope</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>cuda::thread_scope::thread_scope_thread</td>
<td>只同步初始化异步操作的线程</td>
</tr>
<tr>
<td>cuda::thread_scope::thread_scope_block</td>
<td>同步所有或者同一个block中创建的CUDA线程</td>
</tr>
<tr>
<td>cuda::thread_scope::thread_scope_device</td>
<td>同步所有或者同一个block中创建的CUDA线程</td>
</tr>
<tr>
<td>cuda::thread_scope::thread_scope_system</td>
<td>同步系统中创建的所有CPU线程或GPU CUDA线程</td>
</tr>
</tbody></table>
<h2 id="Compute-Capability"><a href="#Compute-Capability" class="headerlink" title="Compute Capability"></a>Compute Capability</h2><p>Compute Capability (SM Version)用来描述硬件的计算能力与支持的功能和指令，其格式为X.Y，其中主版本号X代表核心架构，副版本号Y代表基于X架构的增量更新。</p>
<p>具有相同核心架构的GPU X相同：</p>
<table>
<thead>
<tr>
<th align="center">Architecture</th>
<th align="center">Tesla</th>
<th align="center">Fermi</th>
<th align="center">Kepler</th>
<th align="center">Maxwell</th>
<th align="center">Pascal</th>
<th align="center">Volta</th>
<th align="center">Ampere</th>
</tr>
</thead>
<tbody><tr>
<td align="center">X</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">3</td>
<td align="center">5</td>
<td align="center">6</td>
<td align="center">7</td>
<td align="center">8</td>
</tr>
</tbody></table>
<p>例如，Turing的SM version为7.5，其核心基于Volta。</p>
<p>查询Compute Capability的网站：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a><br>Compute Capability对应支持的功能：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">CUDA文档</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Deemod</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://sognarere.github.io/2022/05/01/CUDA-1/">https://sognarere.github.io/2022/05/01/CUDA-1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://sognarere.github.io" target="_blank">浅眠一梦,不曾醉酒</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2022/05/01/mWXIjvRnOsNQt3g.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/05/15/CUDA-2/"><img class="prev-cover" src="https://s2.loli.net/2022/05/01/mWXIjvRnOsNQt3g.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">CUDA学习记录(二)：矩阵乘的初步实现</div></div></a></div><div class="next-post pull-right"><a href="/2022/04/10/TensorRT%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%85%B6%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B/"><img class="next-cover" src="https://s2.loli.net/2022/05/01/mWXIjvRnOsNQt3g.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">TensorRT学习记录(一)：简介与工作流程</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFCUDA%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">什么是CUDA？</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#GPU-%E4%B8%8E-CPU%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">2.</span> <span class="toc-text">GPU 与 CPU的区别</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CUDA-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">CUDA 编程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kernels"><span class="toc-number">3.1.</span> <span class="toc-text">Kernels</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84"><span class="toc-number">3.2.</span> <span class="toc-text">线程层次结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84"><span class="toc-number">3.3.</span> <span class="toc-text">存储层次结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%82%E6%9E%84%E7%BC%96%E7%A8%8B"><span class="toc-number">3.4.</span> <span class="toc-text">异构编程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5SIMT%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.5.</span> <span class="toc-text">异步SIMT编程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E6%93%8D%E4%BD%9C-%E8%BF%99%E9%83%A8%E5%88%86%E6%B2%A1%E7%9C%8B%E6%87%82%E5%A4%9A%E5%B0%91%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%EF%BC%81%E4%BB%A5%E5%90%8E%E5%86%8D%E5%A1%AB%E5%9D%91"><span class="toc-number">3.5.1.</span> <span class="toc-text">异步操作(这部分没看懂多少！！！！！以后再填坑)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Compute-Capability"><span class="toc-number">3.6.</span> <span class="toc-text">Compute Capability</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Deemod</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'e09c6448bc5cba6d7b7b',
      clientSecret: 'f4d1002c2d190665e210f8521aaa5abc845ea0d7',
      repo: 'SognareRe.github.io',
      owner: 'SognareRe',
      admin: ['SognareRe'],
      id: 'a81f5b9725502a71d93a9eede65d7383',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>